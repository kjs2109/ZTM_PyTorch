{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's use the Jupyter magic function to create a `.py` file for creating DataLoaders. \n",
    "* We can save a code cell's contents to a file using the Jupyter magic `%%writefile filename` - https://ipython.readthedocs.io/en/stable/interactive/magics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py \n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoader's for image classification data. \n",
    "\"\"\"\n",
    "import os \n",
    "from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "NUM_WORKERS = 0  # os.cpu_count() \n",
    "\n",
    "def create_dataloaders(train_dir, test_dir, transform, batch_size): \n",
    "    \"\"\"Create training and testing DataLoader \n",
    "    \n",
    "    Takes in a training directory and testing directory path \n",
    "    and turns them into PyTorch Datasets and then into PyTorch DataLoaders \n",
    "    \n",
    "    Args: \n",
    "        train_dir: train 데이터 폴더의 경로 \n",
    "        test_dir: test 데이터 폴더의 경로 \n",
    "        transform: 데이터에 적용될 transform \n",
    "        batch_size: 배치 사이즈 \n",
    "        num_workers: DataLoader에서 사용할 cpu 개수 \n",
    "        \n",
    "    Return: \n",
    "        (train_dataloader, test_dataloader, class_names)가 튜플 형태로 반환 \n",
    "        class_names는 target_class의 이름이 저장된 리스트  \n",
    "    \"\"\"\n",
    "    \n",
    "    train_data = datasets.ImageFolder(train_dir, transform) \n",
    "    test_data = datasets.ImageFolder(test_dir, transform) \n",
    "    \n",
    "    class_names = train_data.classes \n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        test_data, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py \n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model from the CNN Explainer website. \n",
    "\"\"\"\n",
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "class TinyVGG(nn.Module): \n",
    "    \"\"\"Creates the TinyVGG architecture. \n",
    "    \n",
    "    Replicates the TinyVGG architectoure from CNN explainer website in PyTorch. \n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/ \n",
    "    \n",
    "    Args: \n",
    "        input_shape: 입력 채널 수 \n",
    "        hidden_units: 중간 layer의 채널 수\n",
    "        output_shape: 출력 벡터의 차원 수 (=target class의 수) \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, hidden_unit, output_shape): \n",
    "        super().__init__() \n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_unit, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels=hidden_unit, out_channels=hidden_unit, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        ) \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_unit, out_channels=hidden_unit, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels=hidden_unit, out_channels=hidden_unit, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=hidden_unit*13*13, out_features=output_shape) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.layer_1(x) \n",
    "        # print(x.shape)\n",
    "        x = self.layer_2(x) \n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py \n",
    "\"\"\"\n",
    "Contains functions fo training and testing a PyTorch model \n",
    "\"\"\"\n",
    "import torch \n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, device): \n",
    "    \"\"\"Trains a PyTorch model for a single epoch. \n",
    "    \n",
    "    Turns a target PyTorch model to training mode and then runs through all of the required training steps \n",
    "    (forward pass, loss calculation, optimizer step) \n",
    "    \n",
    "    Args: \n",
    "        model: A PyTorch model to be trained. \n",
    "        dataloader: A DataLoader instance for the model to be trained on. \n",
    "        loss_fn: A PyTorch loss function to minimize. \n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function. \n",
    "        device: A target device to compute on \n",
    "    \n",
    "    Returns: \n",
    "        A tuple of training loss and training accuracy metrics. \n",
    "        In the form (train_loss, train_accuracy)  \n",
    "    \"\"\"\n",
    "    model.train() \n",
    "    train_loss, train_acc = 0, 0 \n",
    "    for batch, (X, y) in enumerate(dataloader): \n",
    "        X, y = X.to(device), y.to(device) \n",
    "        \n",
    "        y_pred = model(X) \n",
    "        \n",
    "        loss = loss_fn(y_pred, y) \n",
    "        train_loss += loss.item() \n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=-1), dim=-1) \n",
    "        train_acc += (y_pred_class == y).sum().item() / len(X) \n",
    "        \n",
    "    train_loss = train_loss / len(dataloader) \n",
    "    train_acc = train_acc / len(dataloader) \n",
    "    \n",
    "    return train_loss, train_acc \n",
    "\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, device): \n",
    "    \"\"\"Tests a PyTorch model for a single epoch. \n",
    "    \n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs a forward pass on a testing dataset.  \n",
    "    \n",
    "    Args: \n",
    "        model: A PyTorch model to be tested. \n",
    "        dataloader: A DataLoader instance for the model to be tested on. \n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data. \n",
    "        device: A target device to compute on \n",
    "    \n",
    "    Returns: \n",
    "        A tuple of testing loss and testing accuracy metrics. \n",
    "        In the form (test_loss, test_accuracy)    \n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    test_loss, test_acc = 0, 0 \n",
    "    with torch.inference_mode(): \n",
    "        for batch, (X, y) in enumerate(dataloader): \n",
    "            X, y = X.to(device), y.to(device) \n",
    "            \n",
    "            test_pred_logits = model(X) \n",
    "            \n",
    "            loss = loss_fn(test_pred_logits, y) \n",
    "            test_loss += loss.item() \n",
    "            \n",
    "            test_pred_labels = test_pred_logits.argmax(dim=-1) \n",
    "            test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels)) \n",
    "            \n",
    "        test_loss = test_loss / len(dataloader) \n",
    "        test_acc = test_acc / len(dataloader) \n",
    "        \n",
    "    return test_loss, test_acc \n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device): \n",
    "    \"\"\"Trains and tests a PyTorch model.  \n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step() functions for a number of epochs, \n",
    "    training and testing the model in the same epoch loop. \n",
    "    \n",
    "    Callculates, prints and stores evaluation metrics throughout. \n",
    "    \n",
    "    Args: \n",
    "        model: A PyTorch model to be trained and tested. \n",
    "        train_dataloader: A DataLoader instance for the model to be trained on. \n",
    "        test_dataloader: A DataLoader instance for the model to be tested on. \n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function. \n",
    "        loss_fn: A PyTorch loss function to calculate loss on both datasets. \n",
    "        epochs: An integer indicating how many epochs to train for. \n",
    "        device: A target device to compute on \n",
    "        \n",
    "    Returns: \n",
    "        A dictionary of training and testing loss as well as training and testing accuracy metrics. \n",
    "        Each metric has a value in a list for each epoch. \n",
    "    \"\"\"\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []} \n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device) \n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, device) \n",
    "        \n",
    "        print(f\"Epoch: {epoch+1} | \"\n",
    "              f\"train_loss: {train_loss:.4f} | \" \n",
    "              f\"train_acc: {train_acc:.4f} | \"\n",
    "              f\"test_loss: {test_loss:.4f} | \"\n",
    "              f\"test_acc: {test_acc:.4f}\") \n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss) \n",
    "        results[\"train_acc\"].append(train_acc) \n",
    "        results[\"test_loss\"].append(test_loss) \n",
    "        results[\"test_acc\"].append(test_acc)  \n",
    "        \n",
    "    return results \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py \n",
    "\"\"\" \n",
    "Contains various utility functions for PyTorch model training and saving. \n",
    "\"\"\"\n",
    "import torch \n",
    "from pathlib import Path \n",
    "\n",
    "def save_model(model, target_dir, model_name): \n",
    "    \"\"\"Saves a PyTorchj model to a target directory. \n",
    "    \n",
    "    Args: \n",
    "        model: A target PyTorch model to. \n",
    "        target_dir: A directory for saving the model to. \n",
    "        model_name; A filename for the saved model. Should include either \".pth\" or \".pt\" as the file extension.  \n",
    "    \"\"\"\n",
    "    target_dir_path = Path(target_dir) \n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or 'pth'\"\n",
    "    model_save_path = target_dir / Path(model_name) \n",
    "    \n",
    "    print(f\"[INfO] Saving model to: {model_save_path}\") \n",
    "    torch.save(obj=model.state_dict(), f=model_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py \n",
    "\"\"\" \n",
    "Trains a PyTorch image classification model using device-agnostic code. \n",
    "\"\"\"\n",
    "import os \n",
    "import torch \n",
    "from going_modular import data_setup, engine, model_builder, utils \n",
    "\n",
    "from torchvision import transforms \n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42) \n",
    "\n",
    "# Setup hyperparameters \n",
    "save_model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\"\n",
    "\n",
    "NUM_EPOCHS = 5 \n",
    "BATCH_SIZE = 32 \n",
    "HIDDEN_UNITS = 10 \n",
    "LEARNING_RATE = 0.001 \n",
    "\n",
    "train_dir = \"data/pizza_steak_sushi/train\" \n",
    "test_dir = \"data/pizza_steak_sushi/test\" \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), \n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir, test_dir, data_transform, BATCH_SIZE) \n",
    "\n",
    "model = model_builder.TinyVGG(input_shape=3, hidden_unit=10, output_shape=len(class_names)).to(device) \n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "\n",
    "engine.train(model=model, \n",
    "             train_dataloader=train_dataloader, \n",
    "             test_dataloader=test_dataloader, \n",
    "             loss_fn=loss_fn, \n",
    "             optimizer=optimizer, \n",
    "             epochs=NUM_EPOCHS, \n",
    "             device=device) \n",
    "\n",
    "utils.save_model(model=model, target_dir=\"saved_models\", model_name=save_model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.3011\n",
      "Epoch: 2 | train_loss: 1.0998 | train_acc: 0.3281 | test_loss: 1.0697 | test_acc: 0.5417\n",
      "Epoch: 3 | train_loss: 1.0869 | train_acc: 0.4883 | test_loss: 1.0808 | test_acc: 0.4924\n",
      "Epoch: 4 | train_loss: 1.0842 | train_acc: 0.3984 | test_loss: 1.0609 | test_acc: 0.5833\n",
      "Epoch: 5 | train_loss: 1.0662 | train_acc: 0.4141 | test_loss: 1.0655 | test_acc: 0.5644\n",
      "[INfO] Saving model to: saved_models\\05_going_modular_script_mode_tinyvgg_model.pth\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
